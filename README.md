<div align="center">
    <h1>
    ProgRE
    </h1>
    <p>
    This is the official implement of Progressive Residual Extraction based Pre-training for Speech Representation Learning  <br>
    </p>
    <!-- <p>
    <img src="docs/logo.png" alt="emobox Logo" style="width: 580px; height: 200px;">
    </p> -->
    <p>
    </p>
</div>

## Guides

**Prog**ressive **R**esidual **E**xtraction based Pre-training (ProgRE) is a speech self-supervised learning model that can progressively extract pitch variation, speaker information, and content information from speech in a residual manner. ProgRE achieves joint performance improvements on various tasks, such as speaker identification, speech recognition, emotion recognition, speech enhancement, and voice conversion.



## Todo List
- [x] ProgRE and HuBERT model under MindSpore Framework
- [x] Pretrained checkpoint of Base version ProgRE and HuBERT under MindSpore Framework
- [x] Error analysis of migrating MindSpore framework models to Pytorch framework
- [x] How to use the pre-trained model in the PyTorch framework
- [ ] Training codes under MindSpore Framework
- [ ] Pretrained checkpoint of Large version ProgRE and HuBERT under MindSpore Framework (84,500 hours)
- [ ] Release 84,500 hours English-Chinese pre-training dataset

## 